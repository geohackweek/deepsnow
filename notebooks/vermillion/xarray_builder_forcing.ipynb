{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to bring in and downsample the forcings\n",
    "\n",
    "This code works off the xarray builder code firs.\n",
    "\n",
    "The goal of this notebook is to load in the forcings data and to create an x.array that is similar in dimesnion and extent to the tolumne data\n",
    "\n",
    "The varaibles for the x array are all of the primary forcings, and they are going to be concatinated based on time. \n",
    "\n",
    "The coordinate system needs to be transformed, the data needs to be subsetted by extent of the tolumne, and downsampled possibly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import gdal\n",
    "import osr\n",
    "import os\n",
    "import time\n",
    "import xarray as xr\n",
    "import pyproj "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "# Define the path to all of the data you want to load\n",
    "path = '/srv/shared/deep_stac/data/forcings/2017/*2017.nc'\n",
    "# Make the path a global varaible and make a list of the files \n",
    "flist=glob.glob(path)\n",
    "print(len(flist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will need to filter the list based on ones we want - Eric's code  \n",
    "\n",
    "#ds=xr.open_mfdataset(flist,  concat_dim='day') #dataset\n",
    "# mf is multiple file dataset \n",
    "#ds.close()\n",
    "#ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workflow for one file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/xarray/conventions.py:448: SerializationWarning: variable 'air_temperature' has _Unsigned attribute but is not of integer type. Ignoring attribute.\n",
      "  stack_char_dim=stack_char_dim, use_cftime=use_cftime)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.plot.plot._PlotMethods at 0x7f83fd43c208>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Working with one dataset is better than many for learning\n",
    "\n",
    "path1 = '/srv/shared/deep_stac/data/forcings/2017/tmmx_2017.nc'\n",
    "#path2 = '/srv/shared/deep_stac/data/forcings/2017/tmmx_2017.nc'\n",
    "d1 = xr.open_dataset(path1)\n",
    "d1\n",
    "\n",
    "\n",
    "# Plot one time step of the data to visualize\n",
    "temp = d1.air_temperature.isel(day=0)\n",
    "#print(temp.isel(lat = 0 , lon = 0, day = 0).values)\n",
    "temp.plot\n",
    "#day[\"air_temperature\"][0].plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the spatial extent of the ASO dataset ... the datset is in UTM and forcing is in Lat/Long ... sad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-04-01\n",
      "2017-05-02\n",
      "2017-08-16\n",
      "2017-07-17\n",
      "2017-03-03\n",
      "2017-06-04\n",
      "2017-07-27\n",
      "2017-07-09\n",
      "2017-01-29\n",
      "[datetime.date(2017, 4, 1), datetime.date(2017, 5, 2), datetime.date(2017, 8, 16), datetime.date(2017, 7, 17), datetime.date(2017, 3, 3), datetime.date(2017, 6, 4), datetime.date(2017, 7, 27), datetime.date(2017, 7, 9), datetime.date(2017, 1, 29)]\n"
     ]
    }
   ],
   "source": [
    "# Bring in a list of the days or change the dates format? \n",
    "aso_path = '/srv/shared/deep_stac/data/snowdepth/netcdf/2017/*int.nc'\n",
    "fname=glob.glob(aso_path)\n",
    "aso_date = []\n",
    "\n",
    "for f in fname:\n",
    "    n = f.split('/')[-1]\n",
    "    t = n.split('_')[0]\n",
    "    t = pd.to_datetime(t).date()\n",
    "    aso_date.append(t)\n",
    "    print(t)\n",
    "print(aso_date)\n",
    "\n",
    "#da.sel(time=slice('2000-01-01', '2000-01-02'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[254008.5 306712.5]\n",
      " [254008.5 306712.5]] [[4230328.5 4230328.5]\n",
      " [4179325.5 4179325.5]]\n",
      "-119.80870340068212 38.18732310852671\n",
      "-119.19368522229072 37.740828269550875\n",
      "<xarray.Dataset>\n",
      "Dimensions:          (crs: 1, day: 365, lat: 10, lon: 15)\n",
      "Coordinates:\n",
      "  * lon              (lon) float64 -119.8 -119.8 -119.7 ... -119.3 -119.3 -119.2\n",
      "  * lat              (lat) float64 38.15 38.11 38.07 38.03 ... 37.86 37.82 37.78\n",
      "  * day              (day) datetime64[ns] 2017-01-01 2017-01-02 ... 2017-12-31\n",
      "  * crs              (crs) uint16 3\n",
      "Data variables:\n",
      "    air_temperature  (day, lat, lon) float32 ...\n",
      "Attributes:\n",
      "    geospatial_bounds_crs:      EPSG:4326\n",
      "    Conventions:                CF-1.6\n",
      "    geospatial_bounds:          POLYGON((-124.7666666333333 49.40000000000000...\n",
      "    geospatial_lat_min:         25.066666666666666\n",
      "    geospatial_lat_max:         49.40000000000000\n",
      "    geospatial_lon_min:         -124.7666666333333\n",
      "    geospatial_lon_max:         -67.058333300000015\n",
      "    geospatial_lon_resolution:  0.041666666666666\n",
      "    geospatial_lat_resolution:  0.041666666666666\n",
      "    geospatial_lat_units:       decimal_degrees north\n",
      "    geospatial_lon_units:       decimal_degrees east\n",
      "    coordinate_system:          EPSG:4326\n",
      "    author:                     John Abatzoglou - University of Idaho, jabatz...\n",
      "    date:                       04 July 2019\n",
      "    note1:                      The projection information for this file is: ...\n",
      "    note2:                      Citation: Abatzoglou, J.T., 2013, Development...\n",
      "    note3:                      Data in slices after last_permanent_slice (1-...\n",
      "    note4:                      Data in slices after last_provisional_slice (...\n",
      "    note5:                      Days correspond approximately to calendar day...\n"
     ]
    }
   ],
   "source": [
    "# Get extent from ASO data: \n",
    "path_aso = '/srv/shared/deep_stac/data/snowdepth/netcdf/2017/20170129_SUPERsnow_depth_3m_int.nc'\n",
    "snow = xr.open_dataset(path_aso,decode_cf=True)\n",
    "\n",
    "# Get the extent of the flight line data: \n",
    "# NOTE: double check first and last are min and max \n",
    "xmin = snow['x'].values[0] #Easting to Lon\n",
    "xmax = snow['x'].values[-1] # Easting to Lon\n",
    "ymax = snow['y'].values[0] # Northing to Lat\n",
    "ymin = snow['y'].values[-1] #Northing to Lat\n",
    "\n",
    "\n",
    "bb = [xmin,xmax,ymin,ymax]\n",
    "crs_snow='32611'\n",
    "crs_temp ='4326'\n",
    "\n",
    "# Project the bounding box to Lat/Long \n",
    "x = np.array([xmin,xmax])\n",
    "y = np.array([ymin,ymax])\n",
    "xv,  yv = np.meshgrid(x, y)\n",
    "print(xv,yv)\n",
    "inProj = pyproj.Proj(init='epsg:32611')\n",
    "outProj = pyproj.Proj(init='epsg:4326')\n",
    "lon_min,lat_min = pyproj.transform(inProj,outProj,xmin,ymin)\n",
    "lon_max,lat_max = pyproj.transform(inProj,outProj,xmax,ymax)\n",
    "print(lon_min,lat_min)\n",
    "print(lon_max,lat_max)\n",
    "\n",
    "#Get the ESPG code for snow\n",
    "#print(snow.transverse_mercator.spatial_ref)\n",
    "\n",
    "# Subset the dataset based on the spatial extent of the ASO data \n",
    "sub_d1 = d1.sel(lon = slice(lon_min,lon_max), lat = slice(lat_min,lat_max))\n",
    "\n",
    "print(sub_d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-119.79125881719555 37.72818507361838\n"
     ]
    }
   ],
   "source": [
    "# How to reproject things! \n",
    "inProj = pyproj.Proj(init='epsg:32611')\n",
    "outProj = pyproj.Proj(init='epsg:4326')\n",
    "lon,lat = pyproj.transform(inProj,outProj,xmin,ymin)\n",
    "print(x2,y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to get Degree Days/ Subset by time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:          (crs: 1, day: 91, lat: 10, lon: 15)\n",
       "Coordinates:\n",
       "  * lon              (lon) float64 -119.8 -119.8 -119.7 ... -119.3 -119.3 -119.2\n",
       "  * lat              (lat) float64 38.15 38.11 38.07 38.03 ... 37.86 37.82 37.78\n",
       "  * day              (day) datetime64[ns] 2017-01-01 2017-01-02 ... 2017-04-01\n",
       "  * crs              (crs) uint16 3\n",
       "Data variables:\n",
       "    air_temperature  (day, lat, lon) float32 ...\n",
       "Attributes:\n",
       "    geospatial_bounds_crs:      EPSG:4326\n",
       "    Conventions:                CF-1.6\n",
       "    geospatial_bounds:          POLYGON((-124.7666666333333 49.40000000000000...\n",
       "    geospatial_lat_min:         25.066666666666666\n",
       "    geospatial_lat_max:         49.40000000000000\n",
       "    geospatial_lon_min:         -124.7666666333333\n",
       "    geospatial_lon_max:         -67.058333300000015\n",
       "    geospatial_lon_resolution:  0.041666666666666\n",
       "    geospatial_lat_resolution:  0.041666666666666\n",
       "    geospatial_lat_units:       decimal_degrees north\n",
       "    geospatial_lon_units:       decimal_degrees east\n",
       "    coordinate_system:          EPSG:4326\n",
       "    author:                     John Abatzoglou - University of Idaho, jabatz...\n",
       "    date:                       04 July 2019\n",
       "    note1:                      The projection information for this file is: ...\n",
       "    note2:                      Citation: Abatzoglou, J.T., 2013, Development...\n",
       "    note3:                      Data in slices after last_permanent_slice (1-...\n",
       "    note4:                      Data in slices after last_provisional_slice (...\n",
       "    note5:                      Days correspond approximately to calendar day..."
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_chunk = d1.sel(day=slice('2017-01-01',aso_date[0]),lon = slice(lon_min,lon_max), lat = slice(lat_min,lat_max))\n",
    "one_chunk\n",
    "\n",
    "# Run function to get a degree day for each pixel:\n",
    "# note temperature measurements are in K \n",
    "\n",
    "#for d in one_chunk.day:\n",
    "    #if air_temp > :\n",
    "        #count \n",
    "   # else: \n",
    "        #cont \n",
    "# make chunk \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
